# ğŸ“ AI Teaching Assistant for Faculty  
### Agentic RAG-based Auto Planning & Auto Assessment System

## ğŸ“Œ Problem Statement

Faculty members spend a significant amount of time on manual academic tasks such as syllabus analysis, lesson planning, question paper creation, and student answer evaluation.  
Existing AI tools act like generic chatbots and **do not enforce syllabus boundaries, Bloomâ€™s taxonomy, exam patterns, or academic compliance**, making them unsuitable for real academic workflows.

---

## ğŸ’¡ Solution Overview

This project presents an **Agentic AI Teaching Assistant** that automates:

- ğŸ“˜ Lesson planning from syllabus
- ğŸ“ Question paper generation aligned with Bloomâ€™s Taxonomy
- ğŸ“Š Student answer evaluation with explainable feedback

The system is built using **LLMs + Retrieval Augmented Generation (RAG) + Guardrails + Multi-Agent Architecture**, ensuring academic correctness, transparency, and compliance.

---

## ğŸ—ï¸ System Architecture


![Architecture Diagram]("C:\Users\Neelam Sirisha\OneDrive\Pictures\Screenshots\Screenshot 2025-12-13 151746.png")


---

## ğŸ§  Agent Roles

### 1ï¸âƒ£ Orchestrator Agent
- Controls execution flow
- Manages inter-agent communication
- Logs evaluation metrics

### 2ï¸âƒ£ Syllabus Understanding Agent
- Extracts units, topics, learning outcomes
- Converts syllabus PDF into structured JSON

### 3ï¸âƒ£ Lesson Planner Agent
- Allocates topics across academic weeks
- Ensures balanced syllabus coverage

### 4ï¸âƒ£ Assessment Generator Agent
- Generates questions per Bloomâ€™s level
- Follows exam pattern rules
- Avoids repetition and difficulty imbalance

### 5ï¸âƒ£ Evaluation Agent
- Scores student answers using rubrics
- Provides explainable feedback
- Highlights missing concepts

### 6ï¸âƒ£ Compliance Agent (Guardrails)
- Prevents out-of-syllabus content
- Enforces Bloomâ€™s taxonomy balance
- Rejects or regenerates invalid outputs

---

## ğŸ“š RAG Pipeline

1. **Document Ingestion**
   - Syllabus PDF â†’ Text â†’ Chunks (500â€“700 tokens)
   - Embeddings stored in FAISS Vector DB

2. **Contextual Retrieval**
   - Retrieves syllabus-relevant chunks only
   - Filters by unit, topic, and Bloom level

3. **Grounded Generation**
   - LLM generates outputs strictly from retrieved context

---

## ğŸ›¡ï¸ Guardrails

### Hard Guardrails
- Syllabus-only content generation
- Exam pattern enforcement
- Bloom distribution limits

### Soft Guardrails
- Difficulty balancing
- Topic diversity
- No repeated verbs or questions

---

## ğŸ“Š Evaluation Metrics

| Metric | Description |
|------|------------|
| Bloom Alignment Score | Match between intended and generated Bloom level |
| Coverage Completeness | Topics covered vs total syllabus |
| Difficulty Balance | Standard deviation across questions |
| Explainability Score | Quality of feedback provided |

---

## ğŸ–¥ï¸ Streamlit UI Flow

1. **Upload Page**
   - Upload syllabus PDF
   - Select subject and output type

2. **Generation Page**
   - Displays agent execution status
   - Shows intermediate outputs

3. **Results Page**
   - Lesson plan table
   - Generated question paper
   - Bloomâ€™s taxonomy distribution chart
   - Evaluation feedback

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|------|-----------|
| UI | Streamlit |
| Agents | LangChain / CrewAI |
| LLM | Groq / OpenAI |
| Embeddings | SentenceTransformers |
| Vector DB | FAISS |
| Backend | Python |

---

## ğŸ¯ Key Highlights

* Not a chatbot â€” a **rule-enforced academic AI system**
* Fully **syllabus-grounded using RAG**
* **Multi-agent reasoning** with compliance checks
* Designed for **government universities**
* Hackathon-ready & scalable

---

## ğŸ¤ One-Line Pitch

> â€œAn agentic, syllabus-grounded AI Teaching Assistant that automates academic planning and assessment while enforcing Bloomâ€™s taxonomy, exam rules, and compliance â€” something a normal chatbot cannot do.â€

---

## ğŸ”® Future Enhancements

* LMS integration
* Multilingual syllabus support
* Department-level analytics dashboard
* Adaptive learning recommendations
